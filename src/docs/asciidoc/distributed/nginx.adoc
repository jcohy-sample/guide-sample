[[distributed-nginx]]
== Nginx

Nginx 内部进程模型：

image::{oss-images}/nginx01.svg[]

. 在 nginx 启动后，会有一个 master 进程和多个 worker 进程，master 进程主要用来管理 worker 进程，包括：接受信号，将信号分发给 worker 进程，监听 worker 进程工作状态，当 worker 进程退出时(非正常)，启动新的 worker 进程。
基本的网络事件会交给 worker 进程处理。多个 worker 进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的 。一个请求，只可能在一个 worker 进程中处理，一个 worker 进程，不可能处理其它进程的请求。
worker 进程的个数是可以设置的，一般我们会设置与机器 cpu 核数一致，这里面的原因与 nginx 的进程模型以及事件处理模型是分不开的 。
. 当 master 接收到重新加载的信号会怎么处理(./nginx -s reload)?， master 会重新加载配置文件，然后启动新的进程，
使用的新的 worker 进程来接受请求，并告诉老的 worker 进程他们可以退休了，老的 worker 进程将不会接受新的，老的 worker 进程处理完手中正在处理的请求就会退出。
. worker 进程是如何处理用户的请求呢？首先 master 会根据配置文件生成一个监听相应端口的 socket，然后再 faster
出多个 worker 进程，这样每个 worker 就可以接受从 socket 过来的消息（其实这个时候应该是每一个 worker 都有一个 socket，只是这些 socket 监听的地址是一样的）。当一个连接过来的时候，每一个 worker 都能接收到通知，但是
只有一个 worker 能和这个连接建立关系，其他的 worker 都会连接失败，这就是所谓的惊群现在，为了解决这个问题，nginx 提供一个共享锁 accept_mutex，有了这个共享锁后，就会只有一个 worker 去接收这个连接。当一个 worker
进程在 accept 这个连接之后，就开始读取请求

master-workers 的机制的好处

首先，对于每个 worker 进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找
时，也会方便很多。

其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master
进程则很快启动新的 worker 进程。

当然，worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 worker 上的所有请求失败，不过不
会影响到所有请求，所以降低了风险

需要设置多少个 worker

Nginx 同 redis 类似都采用了 io 多路复用机制，每个 worker 都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求， 即使是千上万个请求也不在话下。每个 worker 的线程可以把一个 cpu 的性能
发挥到极致。

所以 worker 数和服务器的 cpu 数相等是最为适宜的。设少了会浪费 cpu，设多了会造成 cpu 频繁切换上下文带来的
损耗。

[source,text]
----
#设置 worker 数量
worker_processes 4
#work 绑定 cpu(4 work 绑定 4cpu)。
worker_cpu_affinity 0001 0010 0100 1000
#work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。
worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000
#连接数
worker_connections 1024
----

这个值是表示每个 worker 进程所能建立连接的最大值，所以，一个 nginx 能建立的最大连接数，应该是 `worker_connections * worker_processes`。当然，这里说的是最
大连接数，对于 HTTP 请求本地资源来说，能够支持的最大并发数量是 `worker_connections * worker_processes`，如果是支
持 http1.1 的浏览器每次访问要占两个连接，所以普通的静态访问最大并发数是： `worker_connections * worker_processes /2`，而如果是 HTTP 作为反向代理来说，最
大并发数量应该是 `worker_connections * worker_processes/4`。

== Nginx 作用以及常见配置

=== 反向代理

在 nginx.conf 配置文件中增加如下配置

[source,text]
----
server {
    listen 80;
    server_name 192.168.11.234;

    location / {

        root html;
        proxy_pass http://localhost:8080;
        index index.html index.htm;
    }
}
----

=== 负载均衡：

默认为轮询

权重：weight 代表权,重默认为 1,权重越高被分配的客户端越多

指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况。 例如：

[source,text]
----
upstream server_pool{
    server 192.168.5.21 weight=1;
    server 192.168.5.22 weight=2;
    server 192.168.5.23 weight=3;
}
----

ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。
例如：


[source,text]
----
upstream server_pool{
    ip_hash;
    server 192.168.5.21:80;
    server 192.168.5.22:80;
}
----

fair（第三方）：按后端服务器的响应时间来分配请求，响应时间短的优先分配。

[source,text]
----
upstream server_pool{
    server 192.168.5.21:80;
    server 192.168.5.22:80;
    fair;
}
----