[[distributed-rabbitmq]]
= RabbitMQ


== RabbitMQ 如何保证消息的顺序性？

消息队列中的若干消息如果是对同一个数据进行操作，这些操作具有前后的关系，必须要按前后的顺序执行， 否则就会造成数据异常。

比如通过 mysql binlog 进行两个数据库的数据同步，由于对数据库的数据操作是具有顺序性的，如果操作顺序搞反，就会造成不可估量的错误。比如数据库对一条数据依次进行了 插入->更新->删除 操作，这个顺序必须是这样，如果
在同步过程中，消息的顺序变成了 删除->插入->更新，那么原本应该被删除的数据，就没有被删除，造成数据的不一致问题。

举例场景：

RabbitMQ：

* 一个 queue，有多个 consumer 去消费，这样就会造成顺序的错误，consumer 从 MQ 里面读取数据是有序的，但是每个 consumer 的执行时间是不固定的，无法保证先读到消息的 consumer 一定先完成操作，这样就会
出现消息并没有按照顺序执行，造成数据顺序错误。
+
image::{oss-images}/rabbitmq01.svg[]
+
* 一个 queue 对应一个 consumer，但是 consumer 里面进行了多线程消费，这样也会造成消息消费顺序错误。
+
image::{oss-images}/rabbitmq02.svg[]

解决方案：

* 拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；这样也会造成吞吐量下降，可以在消费者内部采用多线程的方式取消费。一个 queue 对应一个 consumer
+
image::{oss-images}/rabbitmq03.svg[]
+
* 或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理
+
image::{oss-images}/rabbitmq04.svg[]

== 如何使用 RabbitMQ 解决分布式事务？

分布式事务：不同的服务操作不同的数据源（库或表），保证数据一致性的问题。

解决：采用 RabbitMQ 消息最终一致性的解决方案，解决分布式事务问题。

分布式事务场景：

. 电商项目中的商品库和 ES 库数据同步问题。
. 电商项目中：支付----→订单---→库存，一系列操作，进行状态更改等。

在互联网应用中，基本都会有用户注册的功能。在注册的同时，我们会做出如下操作：

收集用户录入信息，保存到数据库向用户的手机或邮箱发送验证码等等…

如果是传统的集中式架构，实现这个功能非常简单：开启一个本地事务，往本地数据库中插入一条用户数据，发送验证码，提交事务。

但是在分布式架构中，用户和发送验证码是两个独立的服务，它们都有各自的数据库，那么就不能通过本地事物保证操作的原子性。这时我们就需要用到 RabbitMQ（消息队列）来为我们实现这个需求。

在用户进行注册操作的时候，我们为该操作创建一条消息，当用户信息保存成功时，把这条消息发送到消息队列。验证码系统会监听消息，一旦接受到消息，就会给该用户发送验证码。

== RabbitMQ 如何确保消息可靠性？

消息可靠性一般来说由 3 方面来保证：

=== 生产者

RabbitMQ 提供 transaction 事务和 confirm 模式来确保生产者不丢消息；

Transaction 事务机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚 （ channel.txRollback() ） , 如果发送成功则提交事务
（channel.txCommit()），然而，这种方式有个缺点：吞吐量下降。

confirm 模式用的居多：一旦 channel 进入 confirm 模式，所有在该信道上发布的消息都将会被指派一个唯一的 ID（从 1 开始），一旦消息被投递到所有匹配的队列之后；
rabbitMQ 就会发送一个 ACK 给生产者（包含消息的唯一 ID），这就使得生产者知道消息已经正确到达目的队列了；

如果 rabbitMQ 没能处理该消息，则会发送一个 Nack 消息给你，可以进行重试操作。

== 消息队列本身

可以进行消息持久化, 即使 rabbitMQ 挂了，重启后也能恢复数据。如果要进行消息持久化，那么需要对以下 3 种实体均配置持久化

. Exchange：声明 exchange 时设置持久化（durable = true）并且不自动删除(autoDelete = false)
. Queue：声明 queue 时设置持久化（durable = true）并且不自动删除(autoDelete = false)
. message：发送消息时通过设置 deliveryMode=2 持久化消息

=== 消费者

消费者丢数据一般是因为采用了自动确认消息模式，消费者在收到消息之后，处理消息之前，会自动回复
RabbitMQ 已收到消息；如果这时处理消息失败，就会丢失该消息；改为手动确认消息即可！手动确认模式下消费
失败时，不将其重新放入队列（确认重试也不会成功的情形），打印错误信息后，通知相关人员，人工介入处理。

== 如何防止 RabbitMQ 消息重复消费？

保证消息幂等性。幂等性概念：一个请求，不管重复来多少次，结果是不会改变的。

RabbitMQ、RocketMQ、Kafka 等任何队列不保证消息不重复，如果业务需要消息不重复消费，则需要消费端处理业务消息要保持幂等性。

方式一：Redis 的 setNX() , 做消息 id 去重 java 版本目前不支持设置过期时间
方式二：redis的 Incr 原子操作：key 自增，大于 0 返回值大于 0 则说明消费过，(key 可以是消息的 md5 取值, 或者如果消息 id 设计合理直接用 id 做 key)
方式三：数据库去重表，设计一个去重表，某个字段使用 Message 的 key 做唯一索引，因为存在唯一索引，所以重复消费会失败。

== 如何解决消息队列的延时以及过期失效问题?消息队列满了之后该如何处理?有几百万的消息持续积压几小时,说说如何解决?

方案分析

该问题,其本质针对的场景，都是说，可能你的消费端出了问题，不消费了，或者消费的极其极其慢。另外还有可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或
者是你积压的时间太长了，导致比如 rabbitmq 设置了消息过期时间后就没了怎么办？

所以这种问题线上常见的，一般不出，一出就是大问题，一般常见于，举个例子，消费端每次消费之后要写 mysql，结果
mysql 挂了，消费端挂掉了。导致消费速度极其慢。

分析1+话术

这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让他恢复消费速度，然后傻傻的等待几个小时消费完毕。(可行,但是不建议 在面试的时候说)

一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟是 18 万条，1000 多万条，所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来

一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：

. 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 cnosumer 都停掉
. 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍或者 20 倍的 queue 数量
. 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue
. 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据
. 这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据
. 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的 consumer 机器来消费消息

分析2+话术

rabbitmq 是可以设置过期时间的，就是 TTL，如果消息在 queue 中积压超过一定的时间就会被 rabbitmq 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。

这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。

这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。

假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次

分析3+话术

如果走的方式是消息积压在 mq 里，那么如果你很长时间都没处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消
费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。

== 如果让你写一个消息队列,该如何进行架构设计?说一下思路

面试官心理分析

* 你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个mq的架构原理
* 看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来

类似问题

如果让你来设计一个 spring 框架你会怎么做？如果让你来设计一个 dubbo 框架你会怎么做？如果让你来设计一个 mybatis
框架你会怎么做？

回答思路:

. 首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统
. 其次你得考虑一下这个mq的数据要不要落地磁盘吧？那肯定要了，落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的。
. 其次你考虑一下你的mq的可用性啊？
. 能不能支持数据 0 丢失啊？

面试官问你这个问题，其实是个开放题，他就是看看你有没有从架构角度整体构思和设计的思维以及能力。确实这个问题可以刷掉一大批人，因为大部分人平时不思考这些东西。

