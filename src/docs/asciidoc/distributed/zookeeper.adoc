[[distributed-zookeeper]]
== Zookeeper

== ZooKeeper 是什么？

ZooKeeper 是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的
反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

分布式应用程序可以基于 Zookeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、
Master 选举、分布式锁和分布式队列等功能。

Zookeeper 保证了如下分布式一致性特性：

* 顺序一致性
* 原子性
* 单一视图
* 可靠性
* 实时性（最终一致性）

客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接
的 zookeeper 机器来处理。对于写请求，这些请求会同时发给其他 zookeeper 机器并且达成一致后，请求才会返回成
功。因此，随着 zookeeper 的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。

有序性是 zookeeper 中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个
时间戳称为 zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这
个 zookeeper 最新的 zxid。

== Zookeeper Watcher 机制 -- 数据变更通知

Zookeeper 允许客户端向服务端的某个 Znode 注册一个 Watcher 监听，当服务端的一些指定事件触发了这个 Watcher， 服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据 Watcher 通知状态和事件类型
做出业务上的改变。

工作机制：

* 客户端注册 watcher
* 服务端处理 watcher
* 客户端回调 watcher

Watcher 特性总结：

. 一次性: 无论是服务端还是客户端，一旦一个 Watcher 被触发，Zookeeper 都会将其从相应的存储中移除。这样的设计有效的
减轻了服务端的压力，不然对于更新非常频繁的节点，服务端会不断的向客户端发送事件通知，无论对于网络还是
服务端的压力都非常大。
. 客户端串行执行: 客户端 Watcher 回调的过程是一个串行同步的过程。
. 轻量: Watcher 通知非常简单，只会告诉客户端发生了事件，而不会说明事件的具体内容。

客户端向服务端注册 Watcher 的时候，并不会把客户端真实的 Watcher 对象实体传递到服务端，仅仅是在客户端请求中使用 boolean 类型属性进行了标记。

watcher event 异步发送 watcher 的通知事件从 server 发送到 client 是异步的，这就存在一个问题，不同的客户端和服
务器之间通过 socket 进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于Zookeeper 本身提供了 ordering guarantee，即客户端监听事件后，才会感知它所监视 znode 发生了变化。所以我们使用 Zookeeper
不能期望能够监控到节点每次的变化。Zookeeper 只能保证最终的一致性，而无法保证强一致性。

注册 watcher getData、exists、getChildren

触发 watcher create、delete、setData

当一个客户端连接到一个新的服务器上时，watch 将会被以任意会话事件触发。当与一个服务器失去连接的时候，
是无法接收到 watch 的。而当 client 重新连接时，如果需要的话，所有先前注册过的 watch，都会被重新注册。通常
这是完全透明的。只有在一个特殊情况下，watch 可能会丢失：对于一个未创建的 znode 的 exist watch，如果在客户
端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个watch 事件可能会被丢失。

== Zookeeper 选举机制

在介绍之前先了解几个概念

* SID：服务器ID。用来唯一标识一台 ZooKeeper集群中的机器，每台机器不能重复，和myid一致。
* ZXID：事务 ID。ZXID 是一个事务 ID，用来标识一次服务器状态的变更。在某一时刻，集群中的每台机器的 ZXID 值不一定完全一致，这和 ZooKeeper 服务器对于客户端“更新请求”的处理逻辑有关。
* Epoch：每个 Leader 任期的代号。没有 Leader 时同一轮投票过程中的逻辑时钟值是相同的。每投完一次票这个数据就会增加

第一次启动

image::{oss-images}/zookeeper01.svg[]

. 服务器 1 启动，发起一次选举。服务器 1 投自己一票。此时服务器 1 票数一票，不够半数以上（3票），选举无法完成，服务器 1 状态保持为 LOOKING；
. 服务器 2 启动，再发起一次选举。服务器 1 和 2 分别投自己一票并交换选票信息：此时服务器 1 发现服务器 2 的 myid 比自己目前投票推举的（服务器 1）大，更改选票为推举服务器 2。此时服务器 1 票数 0 票，服务器 2 票数 2 票，没有半数以上结果，选举无法完成，服务器 1，2 状态保持 LOOKING
. 服务器 3 启动，发起一次选举。此时服务器 1 和 2 都会更改选票为服务器 3。此次投票结果：服务器 1 为0票，服务器 2 为0票，服务器 3 为 3 票。此时服务器 3 的票数已经超过半数，服务器 3 当选 Leader。服务器 1，2 更改状态为 FOLLOWING，服务器 3 更改状态为 LEADING；
. 服务器 4 启动，发起一次选举。此时服务器 1，2，3 已经不是 LOOKING 状态，不会更改选票信息。交换选票信息结果：服务器 3 为 3 票，服务器 4 为 1 票。此时服务器 4 服从多数，更改选票信息为服务器 3，并更改状态为 FOLLOWING；
. 服务器 5 启动，同 4 一样当小弟。

非第一次启动

. 当 ZooKeeper 集群中的一台服务器出现以下两种情况之一时，就会开始进入 Leader 选举：
.. 服务器初始化启动。
.. 服务器运行期间无法和Leader保持连接。
. 而当一台机器进入 Leader 选举流程时，当前集群也可能会处于以下两种状态：
.. 集群中本来就已经存在一个Leader。
+
对于第一种已经存在 Leader 的情况，机器试图去选举 Leader 时，会被告知当前服务器的 Leader 信息，对于该机器来说，仅仅需要和Leader机器建立连接，并进行状态同步即可。
.. 集群中确实不存在 Leader。
+
假设 ZooKeeper 由 5 台服务器组成，SID 分别为 1、2、3、4、5，ZXID分别为 8、8、8、7、7，并且此时 SID 为 3 的服务器是 Leader。某一时刻， 3 和 5 服务器出现故障，因此开始进行 Leader 选举。
+
SID 为 1、2、4 的机器投票情况： （1，8，1）（EPOCH，ZXID，SID ）, （1，8，2）（EPOCH，ZXID，SID ）, （1，7，4）（EPOCH，ZXID，SID ）
+
选举 Leader 规则： 1,EPOCH大的直接胜出 2,EPOCH相同，事务 id 大的胜出 3,事务 id 相同，服务器 id 大的胜出

== ZooKeeper 分布式锁的实现原理

使用 zookeeper 创建临时序列节点来实现分布式锁，适用于顺序执行的程序，大体思路就是创建临时序列节点，找
出最小的序列节点，获取分布式锁，程序执行完成之后此序列节点消失，通过 watch 来监控节点的变化，从剩下的
节点的找到最小的序列节点，获取分布式锁，执行相应处理。