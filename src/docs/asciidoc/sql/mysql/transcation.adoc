[[sql-mysql-transcation]]
= MySQL 事务


[[web-terms-3]]
== MySQL 的事务？

* 原子性(Atomic):事务中各项操作,要么全做要么全不做,任何一项操作的失败都会导致整个事务的失败
* 一致性(Consistent):事务结束后系统状态是一致的;
* 隔离性(Isolated):并发执行的事务彼此无法看到对方的中间状态;
* 持久性(Durable):事务完成后所做的改动都会被持久化,即使发生灾难性的失败.通过日志和同步备份可以在故障发生后重建数据.

补充:关于事务,在面试中被问到的概率是很高的,可以问的问题也是很多的.首先需要知道的是,只有存在并发数据访问时才需要事务.当多个事务访问同一数据时,可能会存在 5 类问题,包括 3 类数据读取问题(脏读、不可重复读和幻读)和 2 类数据更新问题(第 1 类丢失更新和第 2 类丢失更新).

* 脏读(Dirty Read):A 事务读取 B 事务尚未提交的数据并在此基础上操作,而B事务执行回滚,那么 A 读取到的数据就是脏数据.

[[web-terms-3-tbl]]
.脏读
|===
| 时间 | 转账事务A                   | 取款事务B

| T1   |                             | 开始事务

| T2   | 开始事务                    |

| T3   |                             | 查询账户余额为1000元

| T4   |                             | 取出500元余额修改为500元

| T5   | 查询账户余额为500元(脏读) |

| T6   |                            | 撤销事务余额恢复为1000元

| T7   | 汇入100元把余额修改为600元 |

| T8   | 提交事务                   |
|===

* 不可重复读(Unrepeatable Read):事务 A 重新读取前面读取过的数据,发现该数据已经被另一个已提交的事务 B 修改过了.

[[web-terms-3-2-tbl]]
.不可重复读
|===
| 时间 | 转账事务A                   | 取款事务B

| T1   |                             | 开始事务

| T2   | 开始事务                    |

| T3   |                             | 查询账户余额为1000元

| T4   |       查询账户余额为1000元                      |

| T5   |  |        取出100元修改余额为900元

| T6   |  |        提交事务

| T7   | 查询账户余额为900元(不可重复读) |
|===

* 幻读(Phantom Read):事务 A 重新执行一个查询,返回一系列符合查询条件的行,发现其中插入了被事务 B 提交的行.
** 第1类丢失更新:事务 A 撤销时,把已经提交的事务 B 的更新数据覆盖了.
+
[[web-terms-3-3-tbl]]
|===
| 时间 | 统计金额事务A                   | 转账事务B

| T1   |                             | 开始事务

| T2   | 开始事务                    |

| T3   |  统计总存款为 10000 元                           |

| T4   |                         | 新增一个存款账户存入 100 元

| T5   |  |        提交事务

| T6   |  |       再次统计总存款为 10100 元(幻读)
|===

* 第2类丢失更新:事务 A 覆盖事务 B 已经提交的数据,造成事务 B 所做的操作丢失.

[[web-terms-3-4-tbl]]
|===
| 时间 | 转账事务A              | 取款事务B

| T1   |                             |     开始事务

| T2   |       开始事务              |

| T3   |                             | 查询账户余额为 1000 元

| T4   |         查询账户余额为 1000 元                |

| T5   |  |        取出 100 元将余额修改为 900 元

| T6   |  |       提交事务

| T7   |  汇入 100 元将余额修改为 1100 元|

| T8   |  提交事务|

| T9   |  查询账户余额为 1100 元(丢失更新)|
|===

数据并发访问所产生的问题,在有些场景下可能是允许的,但是有些场景下可能就是致命的,数据库通常会通过锁机制来解决数据并发访问问题,按锁定对象不同可以分为表级锁和行级锁。
按并发事务锁定关系可以分为共享锁和独占锁,具体的内容大家可以自行查阅资料进行了解.直接使用锁是非常麻烦的,为此数据库为用户提供了自动锁机制,只要用户指定会话的事务隔离级别，
数据库就会通过分析 SQL 语句然后为事务访问的资源加上合适的锁,此外,数据库还会维护这些锁通过各种手段提高系统的性能,这些对用户来说都是透明的(就是说你不用理解,事实上我确实也不知道)。
ANSI/ISO SQL 92标准定义了4个等级的事务隔离级别,如下表所示:

[[web-terms-3-5-tbl]]
|===
| 隔离级别        | 脏读   | 不可重复读 | 幻读   | 第一类丢失更新 | 第二类丢失更新

| READ UNCOMMITED | 允许   | 允许       | 允许   | 不允许         | 允许

| READ COMMITTED  | 不允许 | 允许       | 允许   | 不允许         | 允许

| REPEATABLE READ | 不允许 | 不允许     | 允许   | 不允许         | 不允许

| SERIALIZABLE    | 不允许 | 不允许     | 不允许 |                | 不允许
|===

需要说明的是,事务隔离级别和数据访问的并发性是对立的,事务隔离级别越高并发性就越差.所以要根据具体的应用来确定合适的事务隔离级别,这个地方没有万能的原则.

== 不可重复读和幻读有什么区别?

不可重复读 针对的是一份数据的修改

幻读 针对的是行数修改

== MySQL 是如何避免事务并发问题的?

避免事务并发问题是需要付出性能代价的，此时和分布式系统设计一样(CAP定理及base理论)，为了保证一致性就一定会牺牲性能，要做取舍 在 mysql 内部通过加锁的方式实现好了解决方案可供选择，就是配置事务隔离级别

== 默认的级别是什么?

InnoDB 存储引擎默认的事务隔离级别是可重复读(REPEATABLE-READ)

== 如何选择事务隔离级别?

隔离级别越低，事务请求的锁越少相应性能也就越高，如没有特殊要求或有错误发生，使用默认的隔离级别即可，如果系统中有高频读写并且对一致性要求高那么就需要比较高的事务隔离级别甚至串行化。

== 靠缓存可以提升高事务隔离级别的性能吗?

提升事务级别的目的本质是提供更高的数据一致性，如果前置有缓存，那么缓存只能提供高效读并不能保证数据及时一致性，相反的我们还需要对缓存管理有额外的开销。

== MySQL 事务隔离是如何实现的?

隔离的实现主要是读写锁和 MVCC

== 什么是一致性非锁定读和锁定读?

一致性非锁定读（Consistent Non-locking Read）和锁定读（Locking Read）是数据库中两种不同的读取方式。

=== 锁定读

锁定读（也称为悲观读）是一种读取数据的方法，它在读取数据时会对相关的数据进行锁定，以防止其他事务对其进行修改。
锁定读会在读取操作期间保持数据的完整性和一致性，但可能会影响并发性能，因为其他事务需要等待锁定释放才能进行修改操作。

使用到了读写锁 读写锁是最简单直接的的事务隔离实现方式

* 每次读操作需要获取一个共享(读)锁，每次写操作需要获取一个写锁。
* 共享锁之间不会产生互斥，共享锁和写锁之间、以及写锁与写锁之间会产生互斥。
* 当产生锁竞争时，需要等待其中一个操作释放锁后，另一个操作才能获取到锁。

锁机制，解决的就是多个事务同时更新数据，此时必须要有一个加锁的机制

* 行锁(记录锁):解决的就是多个事务同时更新一行数据
* 间隙锁:解决的就是多个事务同时更新多行数据

下列操作属于锁定读

[source,sql]
----
select ... lock in share mode
select ... for update
insert、update、delete
----

=== 非锁定读

非锁定读（也称为无锁读或乐观读）是一种读取数据的方法，它不会对数据进行锁定，并且允许并发的读取操作。在进行非锁定读时，其他事务可以同时对数据进行修改，但是在读取完成后，如果发现数据已被修改，则会进行相应的处理，例如重新读取或者回滚。
这种读取方式通常使用版本控制或者时间戳来实现数据的一致性。

== 说一下 MVCC 内部细节

https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html[InnoDB Multi-Versioning]

Multi-Version Concurrency Control 多版本并发控制，MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问

InnoDB 是一个多版本的存储引擎。它保存有关已更改行的旧版本的信息，以支持并发和回滚等事务特性。这些信息存储在一个称为回滚段的数据结构中的系统表空间或 undo 表空间中。
InnoDB 使用回滚段中的信息来执行事务回滚所需的撤消操作。它还使用这些信息构建行的 早期版本，以实现一致的读取

MVCC 的实现依赖于:隐藏字段、Read View、undo log

隐藏字段

* A 6-byte `DB_TRX_ID` 用来标识最近一次对本行记录做修改 (insert 、update) 的事务的标识符 ，即 最后一次修改本行记录的事务 id。 如果是 delete 操作， 在 InnoDB 存储引擎内部也属于一次 update 操作，即更新行中的一个特殊位 ，将行标识为己删除，并非真正删除。
* A 7-byte `DB_ROLL_PTR` 回滚指针，指向该行的 undo log 。如果该行未被更新，则为空.
* A 6-byte `DB_ROW_ID` 如果没有设置主键且该表没有唯一非空索引时， 会使用该 id 来生成 聚簇索引.

Read View

不同的事务隔离级别中，当有事物在执行过程中修改了数据(更新版本号)，在并发事务时需要判断一 下版本链中的哪个版本是当前事务可见的。为此InnoDB有了ReadView的概念，使用ReadView来记录和 隔离不同事务并发时此记录的哪些版本是对当前访问事物可见的。

undo log

除了用来回滚数据，还可以读取可见版本的数据。以此实现非锁定读

== MySQL 事务一致性，原子性是如何实现的?

首先是通过锁和 mvcc 实现了执行过程中的一致性和原子性

其次是在灾备方面通过 Redo log 实现，Redo log 会把事务在执行过程中对数据库所做的所有修改都记录下来，在之后系统崩溃重启后可以把事务所做的任何修改都恢复出来。

== MySQL 事务的持久性是如何实现的?

使用 Redo log 保证了事务的持久性。当事务提交时，必须先将事务的所有日志写入日志文件进行持久化，就是我们常说的 WAL(write ahead log)机制，如果出现
断电重启便可以从 redolog 中恢复，如果 redolog 写入失败那么也就意味着修改失败整个事务也就直接回滚了。

== 表级锁和行级锁有什么区别?

表级锁:串行化(serializable)时，整表加锁，事务访问表数据时需要申请锁，虽然可分为读锁和写
锁，但毕竟是锁住整张表，会导致并发能力下降，一般是做ddl处理时使用

行级锁:除了串行化(serializable)时 InnoDB使用的都是行级锁，只锁一行数据，其他行数据不影
响，并发能力强。

== 什么是行级锁? MySQL 如何完成的?

行级锁实现比较复杂不是单纯锁住一行数据，是由 mvcc 完成的。

== 什么是共享锁(读锁)?

共享锁或 S 锁，其它事务可以继续加共享锁，但不能加排它锁

== 什么是排它锁(写锁/独占锁)?

排它锁或 X 锁，在进行写操作之前要申请并获得，其它事务不能再获得任何锁。

== 什么是意向锁?

它分为意向共享锁(IS)和意向排他锁(IX)

一个事务对一张表的某行添加共享锁前，必须获得对该表一个 IS 锁或者优先级更高的锁。

一个事务对一张表的某行添加排他锁之前，它必须对该表获取一个 IX 锁。

意向锁属于表锁，它不与 innodb 中的行锁冲突，任意两个意向锁之间也不会产生冲突，但是会与表锁 (S锁和X锁)产生冲突

== 悲观锁和乐观锁的怎么实现？

悲观锁：`select...for update` 是 MySQL 提供的实现悲观锁的方式。
例如：`select price from item where id=100 for update`

此时在 items 表中， id 为 100 的那条数据就被我们锁定了，其它的要执行 `select price from items where id=100 for update` 的事务必须等本次事务提交之后才能执行。
这样我们可以保证当前的数据不会被其它事务修改。MySQL 有个问题是 `select...for update` 语句执行中所有扫描过的行都会被锁上，因此在 MySQL 中用悲观锁务必须确定走了索引，而
不是全表扫描，否则将会将整个数据表锁住。

乐观锁：乐观锁相对悲观锁而言，它认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正
式对数据的冲突与否进行检测，如果发现冲突了，则让返回错误信息，让用户决定如何去做。

利用数据版本号（version）机制是乐观锁最常用的一种实现方式。一般通过为数据库表增加一个数字类型的 "version" 字段，当读取数据时，将 `version` 字段的值一同读出，数据每更新一次，对此 `version` 值 `+1`。当我们提交更新的时候，
判断数据库表对应记录的当前版本信息与第一次取出来的 `version` 值进行比对，如果数据库表当前版本号与第一次
取出来的 `version` 值相等，则予以更新，否则认为是过期数据，返回更新失败。

举例：

[source,sql]
----
## 1: 查询出商品信息
select (quantity,version) from items where id=100;
## 2: 根据商品信息生成订单
insert into orders(id,item_id) values(null,100);
## 3: 修改商品的库存
update items set quantity=quantity-1,version=version+1 where id=100 and version=#{version};
----

== InnoDB 支持哪几种锁?

表锁，行锁，间隙锁，Next-Key 锁等 在 Serializable 中读加共享锁，写加排他锁，读写互斥 两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段(所以叫两段锁)

== 当前读和快照读分别是什么?

当前读 :在锁定读(使用锁隔离事物)的时候读到的是最新版本的数据.

快照读:可重复读(repeatable-read)下 mvcc生效读取的是数据的快照，并不是最新版本的数据(未 提交事物的数据)

== 什么是 XA 协议?

https://dev.mysql.com/doc/refman/8.0/en/xa.html[XA Transactions]

image::{oss-images}/mysql-index11.svg[]

* AP(Application Program):应用程序，定义事务边界(定义事务开始和结束)并访问事务边界内的资源。
* RM(Resource Manger)资源管理器: 管理共享资源并提供外部访问接口。供外部程序来访问数据 库等共享资源。此外，RM还具有事务的回滚能力。
* TM(Transaction Manager)事务管理器:TM是分布式事务的协调者，TM 与每个 RM 进行通信， 负责管理全局事务，分配事务唯一标识，监控事务的执行进度，并负责事务的提交、回滚、失败恢 复等。

. 应用程序 AP 向事务管理器 TM 发起事务请求
. TM 调用 `xa_open()` 建立同资源管理器的会话
. TM 调用 `xa_start()` 标记一个事务分支的开头
. AP 访问资源管理器 RM 并定义操作，比如插入记录操作
. TM 调用 `xa_end()` 标记事务分支的结束
. TM 调用 `xa_prepare()` 通知 RM 做好事务分支的提交准备工作。其实就是二阶段提交的提交请求阶 段。
. TM 调用 `xa_commit()` 通知 RM 提交事务分支，也就是二阶段提交的提交执行阶段。 TM 调用 `xa_close()` 管理与 RM 的会话。
.. 这些接口一定要按顺序执行，比如 `xa_start` 接口一定要在 `xa_end` 之前。此外，这里千万要注意的是事务管理器只是标记事务分支并不执行事务，事务操作最终是由应用程序通知资源管理器完成的。

另外，我们来总结下 XA 的接口

* xa_start:负责开启或者恢复一个事务分支，并且管理 XID 到调用线程
* xa_end:负责取消当前线程与事务分支的关系
* xa_prepare:负责询问 RM 是否准备好了提交事务分支
* xa_commit:通知 RM 提交事务分支
* xa_rollback:通知 RM 回滚事务分支

== 什么是 MySQL XA 事务?

MySQL 的 XA 事务分为两部分:

1. InnoDB 内部本地普通事务操作协调数据写入与 log 写入两阶段提交
2. 外部分布式事务

XA 事务语法示例如下:

[source,text]
----
XA START '自定义事务id';

SQL语句...

XA END '自定义事务id';
XA PREPARE '自定义事务id';
XA COMMIT\ROLLBACK '自定义事务id';
----

XA PREPARE 执行成功后，事务信息将被持久化。即使会话终止甚至应用服务宕机，只要我们将【自定义事务 id】记录下来，后续仍然可以使用它对事务进行 rollback 或者 commit。

== XA 事务与普通事务区别是什么?

XA 事务可以跨库或跨服务器，属于分布式事务，同时 XA 事务还支撑了 InnoDB 内部日志两阶段记录

普通事务只能在单库中执行

== 什么是2pc 3pc?

两阶段提交协议与3阶段提交协议，额外增加了参与的角色保证分布式事务完成更完善

== 是否使用过 select for update? 会产生哪些操作?

select 本身是一个查询语句，查询语句是不会产生冲突的一种行为，一般情况下是没有锁的，用 select for update 会让 select 语句产生一个排它锁(X),
这个锁和 update 的效果一样，会使两个事务无法同时更 新一条记录。

* for update 仅适用于 InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效。
* 在进行事务操作时，通过 "for update" 语句，MySQL 会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。 排他锁包含行锁、表锁。
* InnoDB 默认是行级别的锁，在筛选条件中当有明确指定主键或唯一索引列的时候，是行级锁。否则是表级别。


[source,text]
----
SELECT ... FOR UPDATE [OF column_list][WAIT n|NOWAIT][SKIP LOCKED];
select * from t for update 会等待行锁释放之后，返回查询结果。
select * from t for update nowait 不等待行锁释放，提示锁冲突，不返回结果
select * from t for update wait 5 等待5秒，若行锁仍未释放，则提示锁冲突，不返回结果
select * from t for update skip locked 查询返回查询结果，但忽略有行锁的记录
----

== 说一下 MySQL 死锁的原因和处理方法

* 死锁与锁等待是两个概念
** 如未开启事务，多个客户端执行的insert操作
* 当多个事务同时持有和请求同一资源上的锁而产生循环依赖的时候就产生了死锁。

=== 排查

* 正在运行的任务：`show full processlist`; 找到卡主的进程
* 解开死锁: `UNLOCK TABLES` ;
* 查看当前运行的事务: `SELECT * FROM information_schema.INNODB_TRX`;
* 当前出现的锁: `SELECT * FROM information_schema.INNODB_LOCKS`;
* 观察错误日志 查看 InnoDB 锁状态: show status like "innodb_row_lock%";
** Innodb_row_lock_current_waits:当前正在等待锁定的数量;
** Innodb_row_lock_time :从系统启动到现在锁定的总时间长度，单位ms;
** Innodb_row_lock_time_avg :每次等待所花平均时间;
** Innodb_row_lock_time_max:从系统启动到现在等待最长的一次所花的时间;
** Innodb_row_lock_waits :从系统启动到现在总共等待的次数。
* kill id 杀死进程

=== 解决

* 死锁无法避免，上线前要进行严格的压力测试
* 快速失败: `innodb_lock_wait_timeout` 行锁超时时间
* 拆分 SQL，严禁大事务
* 充分利用索引，优化索引，尽量把有风险的事务 SQL 使用上覆盖索，优化 where 条件前缀匹配，提升 查询速度，引减少表锁
* 无法避免时:
** 操作多张表时，尽量以相同的顺序来访问避免形成等待环路
** 单张表时先排序再操作
** 使用排它锁 比如 for update

== MySQL 会产生几种日志?

* 错误日志(error log): error log 主要记录 MySQL 在启动、关闭或者运行过程中的错误信息，在 MySQL 的配置文件 my.cnf 中， 可以通过 log-error=/var/log/mysqld.log 执行 mysql 错误日志的位置。
* 慢查询日志(slow query log)
** MySQL 的慢查询日志是 MySQL 提供的一种日志记录，它用来记录在 MySQL 中响应时间超过阀值的语句，具体指运行时间超过 `long_query_time` 值的SQL，则会被记录到慢查询日志中。
** `long_query_time` 的默认值为 10，意思是运行 10 秒以上的语句。
** 由他来查看哪些 SQL 超出了我们的最大忍耐时间值，比如一条 SQL 执行超过 5 秒钟，我们就算慢 SQL，希望能收集超过 5 秒的 SQL，结合之前 explain 进行全面分析。
** 默认情况下，MySQL 数据库没有开启慢查询日志，需要我们手动来设置这个参数。
** 当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的 性能影响。慢查询日志支持将日志记录写入文件。
+
在生产环境中，如果要手工分析日志，查找、分析SQL，显然是个体力活，MySQL 提供了日志分析工具 `mysqldumpslow`。

* 一般查询日志(general log): general log 记录了客户端连接信息以及执行的 SQL 语句信息，通过 MySQL 的命令
* 重写日志(redo log)
* 回滚日志(undo log)
* 二进制日志(bin log)

== bin log 作用是什么?

MySQL 的bin log日志是用来记录MySQL中增删改时的记录日志。

当你的一条 SQL 操作对数据库中的内容进行了更新，就会增加一条 bin log 日志。
查询操作不会记录到bin log中。

bin log最大的用处就是进行主从复制，以及数据库的恢复。

== redo log 作用是什么?

redo log 是一种基于磁盘的数据结构，用来在 MySQL 宕机情况下将不完整的事务执行数据纠正，redo 日志记录事务执行后的状态。

当事务开始后，redo log 就开始产生，并且随着事务的执行不断写入 redo log file 中。redo log file 中记录了 xxx 页做了 xx 修改的信息，我们都知道数据库的更新操作会在内存中先执行，最后刷入磁盘。

redo log 就是为了恢复更新了内存但是由于宕机等原因没有刷入磁盘中的那部分数据。

== undo log 作用是什么?

undo log 主要用来回滚到某一个版本，是一种逻辑日志。

undo log 记录的是修改之前的数据，比如:当 delete 一条记录时，undo log 中会记录一条对应的 insert 记录，从而保证能恢复到数据修改之前。在执行事务回滚的时候，就可以通过 undo log 中的记录内容并以此进行回滚。

undo log 还可以提供多版本并发控制下的读取(MVCC)。

== MySQL 日志是否实时写入磁盘?

bin log 刷盘机制是如何实 现的? redo log刷盘机制是如何实现的? undo log刷盘机 制是如何实现的?

磁盘写入固然是比较慢的。

参数:sync_binlog

binlog 写入策略:

1. sync_binlog=0 的时候，表示每次提交事务 binlog 不会马上写入到磁盘，而是先写到 page cache,相 对于磁盘写入来说写 page cache 要快得多,不过在 MySQL 崩溃的时候会有丢失日志的风险。
2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync 写入到磁盘 ; 3、sync_binlog的值大于1 的时候，表示每次提交事务都 先写到 page cache，只有等到积累了 N 个事务
之后才 fsync 写入到磁盘，同样在此设置下 MySQL 崩溃的时候会有丢失 N 个事务日志的风险。 很显然三种模式下，sync_binlog=1 是强一致的选择，选择 0 或者 N 的情况下在极端情况下就会有丢失日
志的风险，具体选择什么模式还是得看系统对于一致性的要求。

innodb_flush_log_at_trx_commit

* 取值0:每秒(一秒钟内提交的事务)写入磁盘 每秒触发一次缓存日志回写磁盘操作，并调用操作系统 fsync刷新IO缓存。
* 取值1:有事务提交就立即刷盘 每次提交事务都立即调用操作系统fsync刷新IO缓存。 取值2:每次事务提交 都写给操作系统 由系统接管什么时候写入磁盘 每次都把redo log写到系统的 page cache中，由系统接管什么时候写入磁盘

时机顺序:

1. 开启事务
2. 查询数据库中需要更新的字段，加载到内存中 形成数据脏页
3. 记录 undo log 到内存缓冲区(用于回滚和 mvcc)并关联 redo log -> 可刷盘
4. 记录 redo log 到内存缓冲区 (用于失败重放)准备提交事务 -> 可刷盘
5. 修改内存中的脏页数据
6. 提交事务触发 redo log 刷盘
7. undo log 和脏页 刷盘
8. 事务成功

redo log 与 binlog 的两阶段提交

redo log 的写入拆成了两个步骤:prepare 和 commit

* prepare: redo log写入 log buffer，并 fsync 持久化到磁盘，在 redo log 事务中记录 2PC 的 XID，在 redo log 事务打上 prepare 标识
* commit: binlog 写入 log buffer，并 fsync 持久化到磁盘，在 binlog 事务中记录 2PC 的 XID，同时在 redo log 事务打上 commit 标识

== MySQL 的 binlog 有有几种录入格式?分别有什么区别?

logbin格式:

* binlog_format=STATEMENT(默认):数据操作的时间，同步时不一致，每一条会修改数据的 sql 语句会记录到 binlog 中。
优点是并不需要记录每一 条 sql 语句和每一行的数据变化，减少了 binlog 日志量，节约IO，提高性能。
缺点是在某些情况下会导致 master-slave 中的数据不一致( 如 sleep() 函 数， last_insert_id()，以及 user-defined functions(udf)等会出现问题)
* binlog_format=ROW:批量数据操作时，效率低 不记录每条 sql 语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了。而且不会出现某些特定情况下的存储过程、或 function、或 trigger 的调用和触发无法被正确复制的问题。
缺点是会产生大量的日志，尤其是 alter table 的时 候会让日志暴涨。
* binlog_format=MIXED:是以上两种 level 的混合使用，有函数用 ROW，没函数用 STATEMENT，但是无法识别系统变量

== MySQL 集群同步时为什么使用 binlog?优缺点是什么?

* binlog 是 mysql 提供的日志，所有存储引擎都可用。
* 支持增量同步
* binlog 还可以供其他中间件读取，比如同步到 hdfs 中
* 如果复制表数据:
** 不支持某个阶段回放
** 直接复制数据过程中一旦中断复制(比如断网)，很难确定复制的offset


